{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YoloCropper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tvikDbmZ0Nr"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Check tensorflow version\n",
        "print(\"Using Tensorflow %s\\n\" % (tf.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2fOSfzxZ6iK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mPq1zPIZ6ks"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "from sklearn import metrics\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxL6jH_4V1i5"
      },
      "source": [
        "pixels = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckc0EioEZ6sJ"
      },
      "source": [
        "from tensorflow import keras\n",
        "#model = keras.models.load_model(\"/content/gdrive/MyDrive/stanford40IterationwithoutVal.h5\")\n",
        "\n",
        "YoloModel = keras.models.load_model(\"/content/gdrive/MyDrive/YoloModel.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeqPz_PFZ6uh"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feb_SQ9dJ6dh"
      },
      "source": [
        "# YoloModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ6_SC_rKnGz"
      },
      "source": [
        "**Yolo Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4pN4rVPKmHt"
      },
      "source": [
        "def load_image_pixels(filename, shape):\n",
        "  # load image to get its shape\n",
        "  image = load_img(filename)\n",
        "  width, height = image.size\n",
        "\n",
        "  # load image with required size\n",
        "  image = load_img(filename, target_size=shape)\n",
        "  image = img_to_array(image)\n",
        "\n",
        "  # grayscale image normalization\n",
        "  image = image.astype('float32')\n",
        "  image /= 255.0\n",
        "\n",
        "  # add a dimension so that we have one sample\n",
        "  image = expand_dims(image, 0)\n",
        "  return image, width, height"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T57y6S1NKmJ_"
      },
      "source": [
        "class BoundBox:\n",
        "  def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "    self.xmin = xmin\n",
        "    self.ymin = ymin\n",
        "    self.xmax = xmax\n",
        "    self.ymax = ymax\n",
        "    self.objness = objness\n",
        "    self.classes = classes\n",
        "    self.label = -1\n",
        "    self.score = -1\n",
        "\n",
        "  def get_label(self):\n",
        "    if self.label == -1:\n",
        "      self.label = np.argmax(self.classes)\n",
        "    \n",
        "    return self.label\n",
        "  \n",
        "  def get_score(self):\n",
        "    if self.score == -1:\n",
        "      self.score = self.classes[self.get_label()]\n",
        "    return self.get_score\n",
        "\n",
        "def _sigmoid(x):\n",
        "  return 1. /(1. + np.exp(-x))\n",
        "\n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\tgrid_h, grid_w = netout.shape[:2]\n",
        "\tnb_box = 3\n",
        "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\tnb_class = netout.shape[-1] - 5\n",
        "\tboxes = []\n",
        "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        " \n",
        "\tfor i in range(grid_h*grid_w):\n",
        "\t\trow = i / grid_w\n",
        "\t\tcol = i % grid_w\n",
        "\t\tfor b in range(nb_box):\n",
        "\t\t\t# 4th element is objectness score\n",
        "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
        "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
        "\t\t\t# first 4 elements are x, y, w, and h\n",
        "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
        "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
        "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "\t\t\t# last elements are class probabilities\n",
        "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
        "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "\t\t\tboxes.append(box)\n",
        "\treturn boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1sMxvz5KmMd"
      },
      "source": [
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\tnew_w, new_h = net_w, net_h\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjMe04PkKmO5"
      },
      "source": [
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1:\n",
        "\t\t\treturn 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3:\n",
        "\t\t\t return 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x3\n",
        " \n",
        "def bbox_iou(box1, box2):\n",
        "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\tintersect = intersect_w * intersect_h\n",
        "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\tunion = w1*h1 + w2*h2 - intersect\n",
        "\treturn float(intersect) / union\n",
        " \n",
        "def do_nms(boxes, nms_thresh):\n",
        "\tif len(boxes) > 0:\n",
        "\t\tnb_class = len(boxes[0].classes)\n",
        "\telse:\n",
        "\t\treturn\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
        "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
        "\n",
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
        "\t# enumerate all boxes\n",
        "\tfor box in boxes:\n",
        "\t\t# enumerate all possible labels\n",
        "\t\tfor i in range(len(labels)):\n",
        "\t\t\t# check if the threshold for this label is high enough\n",
        "\t\t\tif box.classes[i] > thresh:\n",
        "\t\t\t\tv_boxes.append(box)\n",
        "\t\t\t\tv_labels.append(labels[i])\n",
        "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
        "\t\t\t\t# don't break, many labels may trigger for one box\n",
        "\treturn v_boxes, v_labels, v_scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYg6hpJuKmT6"
      },
      "source": [
        "# define the anchors\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
        "\n",
        "# define the probability threshold for detected objects\n",
        "class_threshold = 0.6\n",
        "\n",
        "# define the labels\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
        "\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
        "\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
        "\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
        "\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
        "\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
        "\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
        "\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
        "\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "HARLabels = [\"applauding\", \"blowing_bubbles\", \"brushing_teeth\", \"cleaning_the_floor\", \"climbing\",\n",
        "               \"cooking\", \"cutting_trees\", \"cutting_vegetables\", \"drinking\", \"feeding_a_horse\", \"fishing\",\n",
        "               \"fixing_a_bike\",\"fixing_a_car\", \"gardening\", \"holding_an_umbrella\", \"jumping\", \"looking_through_a_microscope\",\n",
        "               \"looking_through_a_telescope\", \"phoning\", \"playing_guitar\", \"playing_violin\", \"pouring_liquid\", \"pushing_a_cart\",\n",
        "               \"reading\", \"riding_a_bike\", \"riding_a_horse\", \"rowing_a_boat\", \"running\", \"shooting_an_arrow\", \"smoking\", \"taking_photos\",\n",
        "               \"texting_message\", \"throwing_frisby\", \"using_a_computer\", \"walking_the_dog\", \"washing_dishes\", \"watching_TV\", \"waving_hands\",\n",
        "               \"writing_on_a_board\", \"writing_on_a_book\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqQ1QdKXKmRa"
      },
      "source": [
        "  from google.colab.patches import cv2_imshow\n",
        "\n",
        "  def draw_boxesV2(filename, v_boxes, v_labels, v_scores):\n",
        "\n",
        "    img = cv2.imread(filename)\n",
        "    H, W, C = img.shape\n",
        "    print(img.shape)\n",
        "\n",
        "    for i in range(len(v_boxes)):\n",
        "      box = v_boxes[i]\n",
        "      y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "      width, height = x2 - x1, y2 - y1\n",
        "      if v_labels[i] == \"person\":\n",
        "        x1 = max(0,x1)\n",
        "        x2 = max(0,x2)\n",
        "        y1 = max(0,y1)\n",
        "        y2 = max(0,y2)\n",
        "\n",
        "        x1 = min (x1, W)\n",
        "        x2 = min (x2, W)\n",
        "        y1 = min (y1, H)\n",
        "        y2 = min (y2, H)\n",
        "\n",
        "        if x1==x2 or y1==y2:\n",
        "          continue\n",
        "        cropped_img = img[y1:y2,x1:x2]\n",
        "        cv2_imshow(cropped_img)\n",
        "        new_filename = filename.split('.')[0] + '_' + str(i) + '.' + filename.split('.')[1]\n",
        "        cv2.imwrite(new_filename ,cropped_img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jkHm9K4LXQc"
      },
      "source": [
        "**HAR Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3fVfa3FXAUA"
      },
      "source": [
        "from numpy import expand_dims\n",
        "def load_image_pixels(filename, shape):\n",
        "  # load image to get its shape\n",
        "  image = load_img(filename)\n",
        "  width, height = image.size\n",
        "\n",
        "  # load image with required size\n",
        "  image = load_img(filename, target_size=shape)\n",
        "  image = img_to_array(image)\n",
        "\n",
        "  # grayscale image normalization\n",
        "  image = image.astype('float32')\n",
        "  image /= 255.0\n",
        "\n",
        "  # add a dimension so that we have one sample\n",
        "  image = expand_dims(image, 0)\n",
        "  return image, width, height"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7hfb35ZLdr5"
      },
      "source": [
        "def classify_image(image):\n",
        "\n",
        "  # define the expected input shape for the model\n",
        "  input_w, input_h = pixels, pixels\n",
        "\n",
        "  image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
        "\n",
        "  # make prediction\n",
        "  yhat = model.predict(image)\n",
        "\n",
        "  #print(cam.shape)\n",
        "  print(yhat.shape)\n",
        "  category = np.argmax(yhat)\n",
        "  print(category)\n",
        "  print(HARLabels[category])\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcU4mFcYaf4R"
      },
      "source": [
        "import os\n",
        "\n",
        "def format_dataset():\n",
        "    path = \"/content/gdrive/MyDrive/standford_tvt_ds_seed_13_test\"\n",
        "    label_set = set()\n",
        "    count = 0\n",
        "    \n",
        "    # iterate through the names of contents of the folder\n",
        "    for folder_path in os.listdir(path):\n",
        "\n",
        "      new_path = path + \"/\" + folder_path\n",
        "\n",
        "      print(count)\n",
        "\n",
        "      for img_path in os.listdir(new_path):\n",
        "        count = count + 1\n",
        "        print(img_path)\n",
        "        # define the expected input shape for the model\n",
        "        input_w, input_h = 416, 416\n",
        "\n",
        "        photo_filename = new_path + \"/\" + img_path\n",
        "\n",
        "        print(photo_filename)\n",
        "\n",
        "        #img = cv2.imread(photo_filename)\n",
        "        #cv2_imshow(photo_filename)\n",
        "\n",
        "        image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
        "\n",
        "        # make prediction\n",
        "        yhat = YoloModel.predict(image)\n",
        "        # summarize the shape of the list of arrays\n",
        "        print([a.shape for a in yhat])\n",
        "        \n",
        "        boxes = list() \n",
        "        for i in range(len(yhat)):\n",
        "          # decode the output of the network\n",
        "          boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
        "       \n",
        "        # correct the sizes of the bounding boxes for the shape of the image\n",
        "        correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "\n",
        "        # suppress non-maximal boxes\n",
        "        do_nms(boxes, 0.5)\n",
        "\n",
        "        # get the details of the detected objects\n",
        "        v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\n",
        "        # summarize what we found\n",
        "        for i in range(len(v_boxes)):\n",
        "          print(v_labels[i], v_scores[i])\n",
        "        \n",
        "        # draw what we found\n",
        "        draw_boxesV2(photo_filename, v_boxes, v_labels, v_scores)\n",
        "\n",
        "        os.remove(photo_filename)\n",
        "\n",
        "    print(count)\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouu4VhQobuf-"
      },
      "source": [
        "format_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Above**"
      ],
      "metadata": {
        "id": "0gVe294M-k9K"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siNeMD_CKmWe"
      },
      "source": [
        "from google.colab import files \n",
        "upload = files.upload()\n",
        "\n",
        "for fn in upload.keys():\n",
        "  photo_filename = '/content/' + fn\n",
        "\n",
        "  # define the expected input shape for the model\n",
        "  input_w, input_h = 416, 416\n",
        "\n",
        "  image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
        "\n",
        "  # make prediction\n",
        "  yhat = YoloModel.predict(image)\n",
        "  # summarize the shape of the list of arrays\n",
        "  print([a.shape for a in yhat])\n",
        "  \n",
        "  boxes = list() \n",
        "  for i in range(len(yhat)):\n",
        "    # decode the output of the network\n",
        "    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
        " \n",
        "  # correct the sizes of the bounding boxes for the shape of the image\n",
        "  correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "\n",
        "  # suppress non-maximal boxes\n",
        "  do_nms(boxes, 0.5)\n",
        "\n",
        "  # get the details of the detected objects\n",
        "  v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\n",
        "  # summarize what we found\n",
        "  for i in range(len(v_boxes)):\n",
        "    print(v_labels[i], v_scores[i])\n",
        "  \n",
        "  # draw what we found\n",
        "  draw_boxesV2(photo_filename, v_boxes, v_labels, v_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RP1xg7ugeRh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}